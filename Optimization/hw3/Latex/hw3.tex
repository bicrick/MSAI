\documentclass[12pt,letterpaper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{parskip}

\title{The University of Texas at Austin\\
\large Optimization\\
\large Homework 3}
\author{Patrick Brown\\
EID: pbb468}
\date{}

\begin{document}

\maketitle

\hrule

\section{Problem 1: Computing the Dual of a Linear Program}

\subsection{Question}
Consider the following LP. Compute its dual.

\begin{align*}
\text{min} : &\quad x_1 - x_2 \\
\text{s.t.} : &\quad 2x_1 + 3x_2 - x_3 + x_4 \leq 0 \\
              &\quad 3x_1 + x_2 + 4x_3 - 2x_4 \geq 3 \\
              &\quad -x_1 - x_2 + 2x_3 + x_4 = 6 \\
              &\quad x_1 \leq 0 \\
              &\quad x_2, x_3 \geq 0.
\end{align*}

\subsection{Solution}

To compute the dual of the given linear program (LP), we need to follow systematic steps to transform the primal LP into its dual form.

\subsubsection{Step 1: Convert Primal LP to Standard Form}

First, we need to express the primal LP in a standard form where all variables are non-negative, and all constraints are equalities.

\begin{itemize}
    \item For $x_1 \leq 0$, let $x_1' = -x_1$ so that $x_1' \geq 0$ and $x_1 = -x_1'$
    \item $x_4$ is unrestricted, so let $x_4 = x_4' - x_4''$ where $x_4', x_4'' \geq 0$
    \item Convert inequalities to equalities by introducing slack variables $s_1 \geq 0$ and $s_2 \geq 0$
\end{itemize}

The standard form of the primal LP becomes:

\begin{align*}
\text{Minimize:} \quad & -x_1' - x_2 \\
\text{Subject to:} \quad
& -2x_1' + 3x_2 - x_3 + (x_4' - x_4'') + s_1 = 0 \\
& -3x_1' + x_2 + 4x_3 - 2(x_4' - x_4'') - s_2 = 3 \\
& x_1' - x_2 + 2x_3 + (x_4' - x_4'') = 6 \\
& x_1', x_2, x_3, x_4', x_4'', s_1, s_2 \geq 0
\end{align*}

\subsubsection{Step 2: Set Up the Dual LP}

For each constraint in the primal, we introduce a dual variable:
\begin{itemize}
    \item $y_1$ for the first constraint
    \item $y_2$ for the second constraint
    \item $y_3$ for the third constraint
\end{itemize}

\subsubsection{Step 3: Formulate the Dual Objective Function}

The dual objective function is formed from the right-hand side of the primal constraints:

\begin{equation*}
\text{Maximize:} \quad 0y_1 + 3y_2 + 6y_3
\end{equation*}

\subsubsection{Step 4: Formulate the Dual Constraints}

For each variable in the primal, we create a constraint in the dual:

\begin{align*}
x_1': \quad & -2y_1 - 3y_2 + y_3 \leq -1 \\
x_2: \quad & 3y_1 + y_2 - y_3 \leq -1 \\
x_3: \quad & -y_1 + 4y_2 + 2y_3 \leq 0 \\
x_4': \quad & y_1 - 2y_2 + y_3 \leq 0 \\
x_4'': \quad & -y_1 + 2y_2 - y_3 \leq 0 \\
s_1: \quad & y_1 \leq 0 \\
s_2: \quad & -y_2 \leq 0
\end{align*}

\subsubsection{Step 5: Simplify the Dual LP}

Combining the constraints for $x_4'$ and $x_4''$, we get:

\begin{equation*}
y_1 - 2y_2 + y_3 = 0
\end{equation*}

The final dual LP is:

\begin{align*}
\text{Maximize:} \quad & 3y_2 + 6y_3 \\
\text{Subject to:} \quad
& 2y_1 + 3y_2 - y_3 \geq 1 \\
& 3y_1 + y_2 - y_3 \leq -1 \\
& -y_1 + 4y_2 + 2y_3 \leq 0 \\
& y_1 - 2y_2 + y_3 = 0 \\
& y_1 \leq 0, \quad y_2 \geq 0, \quad y_3 \text{ unrestricted}
\end{align*}

This is the dual of the given linear program.

\newpage
\section{Problem 2: Matrix Equivalence Statements}

\subsection{Question}
For a given matrix $A$, show that the following two statements are equivalent:

(i) $Ax \geq 0$ and $x \geq 0$ implies that $x_1 = 0$.

(ii) There exists some vector $p > 0$ such that $p^\top A \leq 0$, and $p^\top A_1 < 0$ (strict inequality), where $A_1$ denotes the first column of $A$.

\subsection{Solution}
\textbf{Proof of Equivalence:}

To show that statements (i) and (ii) are equivalent, we will prove two implications:

\begin{enumerate}
    \item (i) $\Rightarrow$ (ii): Assuming (i) holds, we will show that (ii) must also hold.
    \item (ii) $\Rightarrow$ (i): Assuming (ii) holds, we will demonstrate that (i) must be true.
\end{enumerate}

\textbf{Proof of (i) $\Rightarrow$ (ii):}

\textbf{Assumption (i):} For all $x \geq 0$, if $Ax \geq 0$, then $x_1 = 0$.

\textbf{Goal:} Show that there exists a vector $p > 0$ such that $p^\top A \leq 0$ and $p^\top A_1 < 0$.

\textbf{Proof:}

\begin{enumerate}
    \item \textbf{Define the Set $S$:}
    Let $S = \{ x \in \mathbb{R}^n \mid x \geq 0, \, x_1 = 1, \, Ax \geq 0 \}$.
    
    From assumption (i), there is no $x \geq 0$ with $x_1 = 1$ satisfying $Ax \geq 0$. Therefore, $S$ is empty.

    \item \textbf{Apply the Separating Hyperplane Theorem:}
    Since $S$ is an empty convex set, there exists a non-zero vector $p \in \mathbb{R}^n$ such that:
    
    \[p^\top x \leq 0 \quad \text{for all } x \geq 0, \, x_1 = 1, \, Ax \geq 0.\]

    \item \textbf{Characterize $p$:}
    \begin{itemize}
        \item \textbf{Positivity of $p$:}
        Since $x \geq 0$ and $x_1 = 1$, $p$ must satisfy $p_i \geq 0$ for $i \geq 2$, and $p_1 \leq 0$.
        \item \textbf{Non-Zero $p$:}
        $p$ cannot be the zero vector because it must separate $S$ from the origin.
        \item \textbf{Strict Inequality for $p_1$:}
        $p_1$ must be strictly negative; otherwise, $p^\top x$ could be positive for some $x \in S$.
    \end{itemize}

    \item \textbf{Derive $p^\top A \leq 0$:}
    For any $x \geq 0$ with $Ax \geq 0$, we have $p^\top x \leq 0$. This implies $p^\top A \leq 0$.

    \item \textbf{Show $p^\top A_1 < 0$:}
    Since $p_1 < 0$ and all other components of $p$ are non-negative, $p^\top A_1 < 0$.
\end{enumerate}

\textbf{Proof of (ii) $\Rightarrow$ (i):}

\textbf{Assumption (ii):} There exists $p > 0$ such that $p^\top A \leq 0$ and $p^\top A_1 < 0$.

\textbf{Goal:} Show that for all $x \geq 0$, if $Ax \geq 0$, then $x_1 = 0$.

\textbf{Proof:}

Suppose there exists $x \geq 0$ with $x_1 > 0$ and $Ax \geq 0$. Then:

\begin{align*}
    p^\top A x &\geq 0 \quad \text{(since both $p$ and $Ax$ are non-negative)} \\
    p^\top A x &= (p^\top A) x \leq 0 \quad \text{(since $p^\top A \leq 0$)}
\end{align*}

This implies $p^\top A x = 0$. However, we can write:

\[p^\top A x = p^\top A_1 x_1 + p^\top A_{2:n} x_{2:n}\]

Since $p^\top A_1 < 0$, $x_1 > 0$, and $p^\top A_{2:n} x_{2:n} \geq 0$, we have:

\[p^\top A x < 0\]

This contradicts our earlier conclusion that $p^\top A x = 0$. Therefore, our assumption must be false, and $x_1$ must be zero whenever $x \geq 0$ and $Ax \geq 0$.

\textbf{Conclusion:} We have shown that (i) $\Rightarrow$ (ii) and (ii) $\Rightarrow$ (i). Therefore, statements (i) and (ii) are equivalent.


\newpage
\section{Problem 3: Infeasibility in Linear Systems}

\subsection{Question}
Consider a set of 500 equations in 100 variables:

\[Ax \leq b,\]

given by

\[a_i^\top x \leq b_i.\]

\subsection{Solution}

To prove this, we will use linear programming duality and exploit the properties of the dual problem to demonstrate the existence of such a subset.

\textbf{Step 1: Formulate an Auxiliary Linear Program}

Since the original system $Ax \leq b$ is infeasible, let's consider an auxiliary linear program that seeks the minimal amount by which we need to relax the constraints to make the system feasible.

\textbf{Primal Problem:}
\begin{align*}
\text{Minimize} \quad & t \\
\text{Subject to} \quad & Ax \leq b + t \mathbf{1} \\
& t \geq 0 \\
& x \in \mathbb{R}^n
\end{align*}

Here, $t$ represents the minimal slack we need to add to the right-hand side to achieve feasibility. Since $Ax \leq b$ is infeasible, the optimal value $t^* > 0$.

\textbf{Step 2: Derive the Dual Problem}

To utilize duality, we formulate the dual of the above primal problem.

\textbf{Dual Problem:}

Let $y \in \mathbb{R}^m$ be the dual variables corresponding to the inequalities $Ax \leq b + t \mathbf{1}$.

\begin{align*}
\text{Maximize} \quad & b^\top y \\
\text{Subject to} \quad & A^\top y = 0 \\
& \mathbf{1}^\top y = 1 \\
& y \geq 0
\end{align*}

\textbf{Explanation:}
\begin{itemize}
\item The constraint $A^\top y = 0$ comes from the fact that the variables $x$ in the primal problem are unrestricted in sign.
\item The constraint $\mathbf{1}^\top y = 1$ corresponds to the slack variable $t$ in the primal problem.
\item The dual objective function $b^\top y$ reflects the primal objective $t$.
\end{itemize}

\textbf{Step 3: Analyze the Dual Problem}

Since the primal problem has an optimal value $t^* > 0$, by strong duality, the dual problem also has an optimal value $b^\top y^* = t^* > 0$.

The constraints $A^\top y^* = 0$ and $y^* \geq 0$ imply that $y^*$ lies in the null space of $A^\top$ and is a non-negative vector. Additionally, $\mathbf{1}^\top y^* = 1$ means that the sum of the components of $y^*$ is 1.

Since $A^\top y^* = 0$, the positive components of $y^*$ correspond to a set of at most $n + 1 = 101$ inequalities (due to the rank-nullity theorem and the fact that the null space can be spanned by $m - \text{rank}(A^\top)$ vectors). Let's denote this set as $I$.

Assume, for contradiction, that the inequalities corresponding to $I$ are feasible. Then there exists an $x$ such that $a_i^\top x \leq b_i$ for all $i \in I$. Multiplying each inequality by $y_i^* > 0$ and summing, we get:

\[\sum_{i \in I} y_i^* a_i^\top x \leq \sum_{i \in I} y_i^* b_i\]

But since $A^\top y^* = 0$, the left side equals zero, leading to:

\[0 \leq b^\top y^* = t^* > 0\]

This is a contradiction. Therefore, the subset $I$ of at most 101 inequalities is itself infeasible.

\textbf{Conclusion:} By using duality and complementary slackness, we have shown that there exists a subset of at most 101 inequalities from the original set that is infeasible.


\end{document}